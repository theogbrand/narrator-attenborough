summary = """
The Persona-Driven Data Synthesis Methodology introduces a revolutionary approach to creating diverse synthetic data using large language models (LLMs). At its core is the Persona Hub, a collection of 1,015,863,523 unique personas automatically curated from web data, representing approximately 13% of the world's population. This hub acts as a distributed carrier of world knowledge, tapping into almost every perspective within an LLM.

The methodology utilizes two scalable approaches for persona creation:

1. Text-to-Persona: Infers personas from web texts by prompting an LLM with questions like "Who is likely to [read/write/like/dislike/...] this text?" The input text detail influences persona description granularity.

2. Persona-to-Persona: Derives new personas based on interpersonal relationships, expanding the collection through six iterations of relationship expansion.

Deduplication strategies ensure uniqueness, including MinHash-based (using n-gram features) and embedding-based methods (using text embedding models with a cosine similarity threshold of 0.9). Quality filtering employs simple heuristics to remove low-quality descriptions.

Persona-driven data synthesis offers several advantages:
- Not limited by seed corpus size
- Generally applicable to various scenarios
- Leverages an LLM's strong roleplay ability
- Compatible with most popular LLMs

Implementation can use zero-shot, few-shot, or persona-enhanced few-shot prompting methods, integrating personas into synthesis prompts alongside other constraints.

Applications are wide-ranging, including:
- Synthesizing mathematical and logical reasoning problems
- Creating diverse instructions (user prompts)
- Generating knowledge-rich texts
- Developing game NPCs
- Creating tools (functions) at scale

In a notable example, 1.09 million math problems were created using GPT-4 and personas. A 7B LLM fine-tuned on 1.07 million of these problems achieved 64.9% accuracy on the MATH benchmark, matching the performance of much larger models. Math experts assessed 200 challenging problems, finding 96.5% valid.

The methodology's potential impact is significant, potentially driving a paradigm shift in synthetic data creation and enabling large-scale simulation of real-world user needs and behaviors. Applications could include product launch prediction, public response forecasting, and virtual society modeling for policy testing.

However, ethical concerns arise:
- Risk of LLM knowledge and capabilities being extracted and replicated
- Potential exposure of training data information
- Increased risk of generating realistic misinformation

Future improvements to the Persona Hub include:
- Refining personas with more detailed descriptions
- Expanding to multimodal LLMs
- Exploring "super personas" to tap into potential super intelligence

While offering exciting possibilities for advancing AI research and applications, this methodology necessitates careful consideration of ethical implications and responsible use to ensure its positive impact on artificial intelligence and beyond.
"""

content_dict = {
    "## Abstract": "\nWe propose a novel persona-driven data synthesis methodology that leverages various perspectives within a large language model (LLM) to create diverse synthetic data. To fully exploit this methodology at scale, we introduce Persona Hub - a collection of 1 billion diverse personas automatically curated from web data. These 1 billion personas ( $\\sim 13 \\%$ of the world's total population), acting as distributed carriers of world knowledge, can tap into almost every perspective encapsulated within the LLM, thereby facilitating the creation of diverse synthetic data at scale for various scenarios. By showcasing Persona Hub's use cases in synthesizing high-quality mathematical and logical reasoning problems, instructions (i.e., user prompts), knowledge-rich texts, game NPCs and tools (functions) at scale, we demonstrate persona-driven data synthesis is versatile, scalable, flexible, and easy to use, potentially driving a paradigm shift in synthetic data creation and applications in practice, which may have a profound impact on LLM research and development. DISCLAIMER: Persona Hub can facilitate synthetic data creation at a billion-scale to simulate diverse inputs (i.e., use cases) from a wide variety of real-world users. If this data is used as input to query a target LLM to obtain its outputs at scale, there is a high risk that the LLM's knowledge, intelligence and capabilities will be dumped and easily replicated, thereby challenging the leading position of the most powerful LLMs (e.g., our approach allows a $7 B L L M$ to achieve $65 \\%$ on MATH, matching the performance of gpt-4-turbo-preview). This tech report is for research purposes only. It is crucial to avoid misuse and ensure ethical and responsible application. We discuss its broad impact and potential concerns in detail in Section 5.\n\n![](https://cdn.mathpix.com/cropped/2024_09_12_4ecca495f94ca08827cag-01.jpg?height=782&width=1489&top_left_y=1493&top_left_x=318)\n\nFigure 1: Personas can work with a wide range of data synthesis prompts (e.g., create a math problem or a user prompt) to guide an LLM to synthesize data with corresponding perspectives. The 1 billion personas in Persona Hub can facilitate synthetic data creation for various data synthesis scenarios at a billion scale.\n",
    "## 1 Introduction": '\nAs synthetic data (Bauer et al., 2024; Liu et al., 2024), typically referring to data generated by models or algorithms rather than directly by humans, becomes increasingly valued (Li et al., 2023b) for training large language models (LLMs), there is a growing interest in data synthesis using LLMs: by simply specifying a data synthesis prompt, an LLM is expected to produce desirable synthetic data.\nIn practice, however, it is non-trivial to create synthetic data at scale: while we can easily scale up the quantity of synthetic data, it is difficult to ensure its diversity scales up as well. Without considering sampling ${ }^{1}$, an LLM can only produce 1 instance given a data synthesis prompt. Therefore, to create diverse synthetic data at scale (e.g., 1 billion diverse math problems), a large number of diverse prompts are needed.\n\nPrevious research tends to diversify the data synthesis prompt through the following two paradigms, but unfortunately, neither can practically achieve scalable synthetic data creation:\n\n- Instance-driven: This approach diversifies the data synthesis prompt by leveraging a seed corpus (i.e., creating new instances based on the instances in the seed corpus). Representative studies include Wang et al. (2022) and Yu et al. (2023). However, under this paradigm, the diversity of the synthesized data mainly comes from the seed instances, making it difficult to truly extend beyond the seed corpus. Given the limited size of a seed corpus in most practical scenarios, it is challenging for this paradigm to scale up the creation of synthetic data.\n- Key-point-driven: This approach diversifies the data synthesis prompt with a curated comprehensive list of key points (or concepts) that can be a topic, a subject, or any knowledge we expect synthetic data to encompass. Representative studies include Li et al. (2024b) and Huang et al. (2024). However, this methodology also faces difficulties in scaling synthetic data creation: it is practically prohibitive to curate a comprehensive list by enumerating all key points across different levels of granularity, unless limited to a narrow and specific domain (e.g., mathematics).\n\nTo practically achieve diverse synthetic data creation at scale, we propose a novel persona-driven data synthesis methodology. This is inspired by the observation that simply adding a persona to a data synthesis prompt can steer the LLM towards the corresponding perspective to create distinctive synthetic data, as shown in Figure 1. Since almost any LLM use case can be associated with a specific persona, we can create all-encompassing synthetic data at scale as long as we construct a comprehensive persona collection.\n\n![](https://cdn.mathpix.com/cropped/2024_09_12_4ecca495f94ca08827cag-02.jpg?height=508&width=1489&top_left_y=1687&top_left_x=318)\n\nFigure 2: From a compression perspective (Del√©tang et al., 2023; Ge et al., 2024), Persona Hub ( $\\sim 10^{10}$ tokens) can be seen as the compressed form of world knowledge (public web text for training LLMs, $\\sim 10^{14}$ tokens) into distributed carriers. On the other hand, the public web text can be seen as the decompressed content created by these personas with their knowledge and experiences.\n\n[^0]Fortunately, personas are very easy to scale up. From massive web data, we automatically construct Persona Hub - a persona collection containing 1 billion diverse personas ( $\\sim 13 \\%$ of the world\'s total population). As Figure 2 shows, these 1 billion personas can be regarded as distributed carriers of world knowledge, and each individual can be associated with their unique knowledge, experience, interest, personality and profession; thus, they can tap into almost every perspective encapsulated within the LLM to create diverse synthetic data at scale, without being limited by the size of a seed corpus. Moreover, in contrast to key points that typically work with specific data synthesis prompts, personas can be combined with almost any data synthesis prompt, benefiting from an LLM\'s strong roleplay ability (Shanahan et al., 2023; Li et al., 2023a; Choi \\& Li, 2024; Wang et al., 2024), making them generally applicable to a variety of data synthesis scenarios.\nWe showcase Persona Hub\'s use cases in large-scale creation of math and logical reasoning problems, instructions (i.e., user prompts), broad-coverage knowledge-rich texts, game NPCs, and tool (function) development. We demonstrate that persona-driven data synthesis is versatile, scalable, flexible, and easy to use, potentially driving a paradigm shift in synthetic data creation and applications in practice, which may have a profound impact on LLM research and development.\n\nTo facilitate research in persona-driven data synthesis, we initially release 200,000 personas from Persona Hub and following synthetic data samples we created with various personas, including:\n\n- 50,000 math problems\n- 50,000 instructions\n- 10,000 game NPCs\n- 50,000 logical reasoning problems\n- 10,000 knowledge-rich texts\n- 5,000 tools (functions)\n\nWe are open to releasing more data when we can better assess the potential risks and concerns, which will be discussed in detail in Section 5.\n\nNote: Our proposed methodology is applicable to almost any popular LLM ${ }^{2}$. The prompts shown in the figures throughout this paper are not exactly the prompt strings we used in our experiments; instead, they are simplified to fit the space and better illustrate the concepts. Interested readers can easily verify our methodology using the persona samples we have released. It is also worth noting that the main focus of this work is on creating new synthetic data, unlike much previous research that focuses on generating synthetic outputs for specific inputs (e.g., a math problem). Therefore, we use the terms "create" and "synthesize" interchangeably throughout the paper.\n',
    "## 2 Persona Hub": {
        "## 2 Persona Hub": "We propose two scalable approaches to derive diverse personas to construct Persona Hub from massive web data: Text-to-Persona and Persona-to-Persona.",
        "### 2.1 Text-to-Persona": 'A person with specific professional experiences and cultural backgrounds will have unique interests in reading and writing. Therefore, from a specific text, we can infer a specific persona who is likely to [read|write|like|dislike|...] the text. Given that text data on the web is virtually unlimited and all-encompassing, we can obtain a wide-ranging collection of personas simply by prompting an LLM with these web texts, as shown in Figure 3.\nThere are many formats (e.g., plain text or structured text) to represent a persona, which can be controlled within the prompt. The granularity of an output persona description can also be adjusted through the prompt. For example, in the first case, a coarse-grained persona might be "a computer scientist", whereas the fine-grained persona is "a machine learning researcher focused on neural network architectures and attention mechanisms". In our practice, we ask the LLM (in the prompt) to output\n\n[^1]![](https://cdn.mathpix.com/cropped/2024_09_12_4ecca495f94ca08827cag-04.jpg?height=565&width=1489&top_left_y=265&top_left_x=318)\n\nFigure 3: The Text-to-Persona approach: it can use any text as input to obtain corresponding personas just by prompting the LLM "Who is likely to [read|write|like|dislike|...] the text?"\n\n![](https://cdn.mathpix.com/cropped/2024_09_12_4ecca495f94ca08827cag-04.jpg?height=651&width=1483&top_left_y=973&top_left_x=321)\n\nFigure 4: Persona descriptions will be fine-grained if input texts involve many detailed elements.\npersona descriptions as specifically as possible. Besides specifying the granularity of persona descriptions in the prompt, input texts can also influence the granularity of persona descriptions. As shown in Figure 4, if an input text (e.g., from a mathematical textbook or an academic paper about superconductivity) contains many detailed elements, the resulting persona description will also be specific and fine-grained. Therefore, by applying the Text-to-Persona approach to massive web text data, we can obtain billions (or even trillions) of diverse personas, encompassing a wide range of aspects across different granularities.',
        "### 2.2 Persona-to-Persona": 'As discussed above, Text-to-Persona is a highly scalable method that can synthesize personas covering almost every aspect. However, it may still miss some personas that have low visibility on the web and thus are less likely to obtain via Text-to-Persona, such as a child, a beggar, or a behind-the-scenes crew member of a movie. To supplement the personas that Text-to-Persona might hardly reach, we propose Persona-to-Persona, which derives personas with interpersonal relationships from those obtained through Text-to-Persona.\nAs shown in Figure 5, the persona about "a child" can be derived from the persona of a nurse at a children\'s hospital (patient-caregiver relationship). Similarly, "a beggar" can be derived from the\n\n![](https://cdn.mathpix.com/cropped/2024_09_12_4ecca495f94ca08827cag-05.jpg?height=481&width=1305&top_left_y=277&top_left_x=407)\n\nFigure 5: Persona-to-Persona obtains diverse personas via interpersonal relationships, which can be easily achieved by prompting the LLM "Who is in close relationship with the given persona?"\npersona of a shelter worker (assistance relationship), and "a behind-the-scenes movie crew member" can be derived from the persona of the movie\'s lead actor (co-worker relationship). According to the six degrees of separation theory (Travers \\& Milgram, 1977), we perform six iterations of persona relationship expansion for each persona obtained through Text-to-Persona, thereby enriching our persona collection even further.',
        "### 2.3 Deduplication": "We first run Text-to-Persona on the RedPajama v2 dataset (Computer, 2023) and then perform Personato-Persona, as described in Sections 2.1 and 2.2. After obtaining billions of personas, it is inevitable that some of the personas will be identical or extremely similar. To ensure the diversity of Persona Hub, we deduplicate these personas in two ways:\n\nMinHash-based Deduplication We use MinHash (Broder, 1997) to deduplicate based on the n-gram features of persona descriptions. Since persona descriptions are usually just 1-2 sentences, much shorter than a document, we simply used 1-gram and a signature size of 128 for MinHash deduplication. We deduplicate at the similarity threshold of 0.9 .\n\nEmbedding-based Deduplication After deduplication based on surface forms (i.e., MinHash with n-gram features), we also adopt embedding-based deduplication. We use a text embedding model (e.g., the text-embedding-3-small model from OpenAI) to compute an embedding for each persona, and then filter out personas with a cosine semantic similarity greater than 0.9.\nNote that although we select 0.9 as the threshold here, we can flexibly adjust it according to specific needs for further deduplication. For instance, when the requirement for the number of instances is not high (e.g., only needing 1 million instances) but the demand for diversity is high, we can further apply a stricter deduplication standard (e.g., discarding personas with a similarity greater than 0.5).\nAfter deduplication and using simple heuristic methods to filter out low-quality persona descriptions, we have harvested a total of $1,015,863,523$ personas, finally forming our Persona Hub.",
    },
    "## 3 Persona-driven Synthetic Data Creation": "\nOur proposed persona-driven data synthesis approach is straightforward and effective, which involves integrating a persona into the appropriate position in a data synthesis prompt. Simple as it appears, it can significantly influence the LLM to adopt the persona's perspective to create synthetic data. Driven by the 1 billion personas in Persona Hub, this approach can easily create diverse synthetic data at a billion scale.\n\n![](https://cdn.mathpix.com/cropped/2024_09_12_4ecca495f94ca08827cag-06.jpg?height=847&width=1482&top_left_y=268&top_left_x=316)\nFigure 6: 0-shot, few-shot and persona-enhanced few-shot prompting methods.\n\nJust as we can use either zero-shot or few-shot methods to prompt an LLM, the persona-driven methodology is also flexible and compatible with various forms of prompts to create synthetic data. As shown in Figure 6, we propose three persona-driven data synthesis prompting methods:\n\n- Zero-shot prompting does not leverage any existing examples (i.e., demonstrations), thereby fully exploiting the model's creativity without being constrained by specific examples.\n- Few-shot prompting can better ensure that the synthesized data meets the requirements by providing some demonstrations.\n- Persona-enhanced few-shot prompting is more effective in enhancing the LLM's persona-driven data synthesis capabilities. However, its drawback is that it requires deriving the corresponding persona for each demonstration in the few-shot prompt beforehand.\n",
    "## 4 Use Cases": {
        "## 4 Use Cases": "We demonstrate the use cases of Persona Hub in various data synthesis scenarios, including the largescale creation of math and logical reasoning problems, instructions (i.e., user prompts), knowledgerich texts, game NPCs, and tool (function) development.\nAs mentioned earlier, the persona-driven approach is general and versatile, making it easily adaptable to different data synthesis scenarios simply by adjusting the data synthesis prompt. Therefore, we will provide a detailed technical discussion only for math problem synthesis (Section 4.1) and skip the detailed discussion for other use cases.",
        "### 4.1 Math Problems": "### 4.1.1 Demonstrations\n\nAs the initial example (Figure 1) shows, when prompting an LLM to create a math problem, adding a persona leads the LLM to create math problems related to that persona. The example in Figure 7(left) further confirms this: when presented with a linguist persona, the LLM will create a math problem in the context of computational linguistics. Moreover, adding a persona does not hinder\n\n![](https://cdn.mathpix.com/cropped/2024_09_12_4ecca495f94ca08827cag-07.jpg?height=747&width=1508&top_left_y=266&top_left_x=299)\n\nFigure 7: A linguist persona with different math problem creation prompts that specify the focus (e.g., geometry) or the difficulty (e.g., Olympiad-level)\nthe flexibility of the prompt - we can still easily specify the focus (Figure 7(middle)) or difficulty (Figure 7(right)) of our desired math problem in the prompt.\n\n![](https://cdn.mathpix.com/cropped/2024_09_12_4ecca495f94ca08827cag-07.jpg?height=633&width=1490&top_left_y=1299&top_left_x=316)\n\nFigure 8: Examples of math problems created with personas of professionals related to the field of mathematics. They tend to be more challenging than those created with general personas because they usually require a deeper and more fine-grained understanding of advanced mathematical knowledge and skills.\n\nThe examples in Figure 7 demonstrate the use of general personas to create math problems. We can certainly employ professionals related to mathematics to create math problems as well. As shown in Figure 8, personas of math professionals ${ }^{3}$ often mention more advanced and granular mathematics knowledge and skills (as discussed earlier in Section 2.1 and Figure 4), which in turn allows the created math problems to cover these mathematical concepts, making them more challenging.\n\n[^2]\n\n### 4.1.2 Evaluation\n\nData We select ${ }^{4} 1.09$ million personas from Persona Hub and employ the 0 -shot prompting method using GPT-4 to create math problems with these personas, which does not leverage any instances from benchmarks like MATH (Hendrycks et al., 2021) during the creation of math problems. This approach allowed us to synthesize 1.09 M math problems. Since this work focuses on creating new synthetic data rather than synthesizing solutions, we simply used gpt-4o (assistant ${ }^{5}$ ) to generate solutions to the created problems. Among these 1.09 M math problems, we randomly hold out 20 k as a synthetic test set to facilitate evaluation. The remaining 1.07 M problems are used for training.\n\nTest sets We use the following two test sets for evaluation:\n\n- Synthetic Test Set (In-distribution): Since the set of the held-out 20K problems is produced in the same way as the 1.07 M training instances, it can be considered an in-distribution test set. To ensure the accuracy of the answers in this test set for increasing the reliability of the evaluation, we additionally generate solutions using gpt-4o ( $\\mathrm{PoT}^{6}$ ) and gpt-4-turbo (assistant) in addition to the solution generated by gpt-4o (assistant). We retain only the test instances where at least two solutions are consistent. The remaining test set consists of 11.6 K test instances.\n- MATH (Out-of-distribution): The most widely recognized benchmark for testing the mathematical reasoning ability of LLMs. Its test set contains 5,000 competitive-level math problems with reference answers. Since we do not use any instances from the MATH dataset for data synthesis or training, we regard the MATH test set as an out-of-distribution test set.\n\nEquality Checking We follow the same evaluation protocol as OpenAI ${ }^{7}$ to check answer equality on the MATH benchmark. For the synthetic test set, we use a similar method, except we use Llama-3-70B-Instruct instead of gpt-4-turbo-preview as the equality checker.\n\nWe simply fine-tune the latest open-sourced 7B LLM - Qwen2-7B (qwe, 2024) with our synthesized 1.07 million math problems and evaluate its greedy decoding outputs on the above two test sets.\n\n|                            Model                            | Model Size | Accuracy (\\%) |\n| :---------------------------------------------------------: | :--------: | :-----------: |\n|                      Open-sourced LLMs                      |            |               |\n|           DeepSeek LLM 67B Chat (Bi et al., 2024)           |    67B     |     53.2      |\n|         Phi-3-Mini-4K-Instruct (Abdin et al., 2024)         |   3.8 B    |     68.3      |\n|            Yi-1.5-34B-Chat (Young et al., 2024)             |    34B     |     70.4      |\n|                Qwen1.5-72B-Chat (Team, 2024)                |    72B     |     60.7      |\n|               Qwen1.5-110B-Chat (Team, 2024)                |    110B    |     73.0      |\n|                Qwen2-7B-Instruct (qwe, 2024)                |     7B     |     72.1      |\n|               Qwen2-72B-Instruct (qwe, 2024)                |    72B     |     77.2      |\n|                     Llama-3-8B-Instruct                     |     8B     |     39.8      |\n|                    Llama-3-70B-Instruct                     |    70B     |     63.5      |\n|                            GPT-4                            |            |               |\n|                   gpt-4-turbo-2024-04-09                    |     ?      |     88.1      |\n|                      gpt-4o-2024-05-13                      |     ?      |     91.2      |\n|                          This work                          |            |               |\n| Qwen2-7B (fine-tuned $w /$ the 1.07M synthesized instances) |     7B     |     79.4      |\n\nTable 1: In-distribution evaluation results on the 11.6 K synthetic test instances.\n\n| [^3]                                                        |               Model                | State-of-the-art LLMs |     |     |\n| :---------------------------------------------------------- | :--------------------------------: | :-------------------: | :-: | --- |\n|                                                             |                                    |                       |     |\n| gpt-4o-2024-05-13                                           |                $?$                 |         76.6          |     |\n| gpt-4-turbo-2024-04-09                                      |                                    |     Accuracy (\\%)     |     |\n| gpt-4-turbo-0125-preview                                    |                $?$                 |         63.4          |     |\n| gpt-4-turbo-1106-preview                                    |                $?$                 |         64.5          |     |\n| gpt-4                                                       |                $?$                 |         52.3          |     |\n| Claude 3.5 Sonnet                                           |                $?$                 |      $71.1^{*}$       |     |\n| Claude 3 Opus                                               |                $?$                 |         63.8          |     |\n| Gemini Pro 1.5 (May 2024)                                   |                $?$                 |      $67.7^{*}$       |     |\n| Gemini Ultra                                                |                $?$                 |      $53.2^{*}$       |     |\n| DeepSeek-Coder-V2-Instruct (Zhu et al., 2024)               | $236 \\mathrm{~B} / 21 \\mathrm{~B}$ |      $75.7^{*}$       |     |\n| Llama-3-70B-Instruct                                        |                70 B                |         52.8          |     |\n| Qwen2-72B-Instruct                                          |                72 B                |      $59.7^{*}$       |     |\n| Qwen2-7B-Instruct                                           |                 7B                 |      $49.6^{*}$       |     |\n| Qwen2-7B (fine-tuned $w /$ the 1.07M synthesized instances) |                                    |          7B           |     |\n\nTable 2: Out-of-distribution evaluation on MATH. Results marked with an asterisk ( ${ }^{*}$ ) may not use the OpenAI's evaluation method. The model fine-tuned with our synthesized 1.07M math problems achieves $64.9 \\%$ on MATH, matching the performance of gpt-4-turbo-preview at only a 7B scale.\n\nTable 1 presents the in-distribution (ID) evaluation results on the 11.6 K synthetic test instances. Among the tested open-source LLMs, Qwen2-72B-Instruct achieves the best result, and the ranking of the other models is generally consistent with their reported performance on other mathematical benchmarks. Our model, with the help of the 1.07 M synthetic math problems, achieves nearly $80 \\%$ accuracy, surpassing all the open-source LLMs. However, considering that the answers in the synthetic test are not absolutely reliable and that our model might be the only one using ID training data, this ID evaluation results should be taken as a reference only.\nWe present the evaluation results on MATH in Table 2. The 7B model fine-tuned with the synthetic training data achieved\n\n![](https://cdn.mathpix.com/cropped/2024_09_12_4ecca495f94ca08827cag-09.jpg?height=671&width=850&top_left_y=1188&top_left_x=971)\n\nFigure 9: Accuracy on MATH with scaling the synthetic instances used for training Qwen2-7B an impressive $64.9 \\%$ accuracy on MATH simply using greedy decoding, outperformed only by gpt-4o, gpt-4-turbo-2024-04-09, Claude 3.5 Sonnet, Gemini Pro 1.5 (May 2024) and DeepSeek-Coder-V2-Instruct.\n\nFigure 9 presents the performance of the model on MATH when trained with synthetic math problems at different scales. Its performance trend generally aligns with the scaling law (Kaplan et al., 2020). Unlike previous research (Yu et al., 2023; Wang et al., 2023; Li et al., 2024a) that performs scaling on in-distribution data (e.g., heavily relying on MATH train data to augment in-distribution data), we did not use any instances from MATH during data synthesis or training. Therefore, in this out-of-distribution (OOD) evaluation setting, achieving performance on MATH that surpasses gpt-4-turbo-preview (1106/0125) is indeed impressive and promising for a 7B model.\nWe examine the quality of our synthesized math problems: we sample 200 challenging problems (involving high school and university-level math knowledge points in China), and have two math\n\n![](https://cdn.mathpix.com/cropped/2024_09_12_4ecca495f94ca08827cag-10.jpg?height=472&width=1537&top_left_y=270&top_left_x=293)\n\nFigure 10: Similarities of math problems created by personas with different similarities: (a) Similarity of math problems when no specific focus is given; (b) Similarity of math problems when the prompt specifies they must be related to finance and probability; (c) Similarity of math problems synthesized by gpt-4o and gpt-35-turbo with persona similarity of 0.9 .\nexperts evaluate their validity. Only 7 out of 200 problems are marked as invalid (e.g., due to insufficient or conflicting conditions), yielding a reliable validity rate of $96.5 \\%$.\nMoreover, we specifically examine the impact of differences in personas within the prompts on the synthesized math problems. We first sample 100 pairs of personas with semantic similarities ${ }^{8}$ of 0.4 , 0.6 , and 0.8 , respectively. For each pair of personas, we use them to create a pair of math problems using greedy decoding (i.e., temperature $=0$ ). Then, we compute the semantic similarity of these math problem pairs and show the results in Figure 10.\nWe can clearly observe that the semantic similarity between synthesized math problems tends to be correlated with but lower than the similarity between their corresponding personas. When we add more specific constraints to the prompts (e.g., math problems about finance and probability), the similarity between the synthesized math problems tends to become higher (Figure 10(b)). In Figure 10(c), we also test the similarity of math problems created by gpt-4o and gpt-35-turbo using highly similar personas (similarity $=0.9$ ). The results indicate that the semantic similarity of the math problems created by gpt-4o and gpt-35-turbo seems not significantly different: most synthesized math problems' similarity falls within the range of 0.6 to 0.75 , which is much lower than the similarity of the personas (0.9). Given these observations, we believe that using the personas in Persona Hub can ensure the diversity of synthesized data - even at a billion scale.",
        "### 4.2 Logical Reasoning Problems": "Similar to math problems, logical reasoning problems can also be easily synthesized. We present examples of typical logical reasoning problems synthesized using our proposed persona-driven methodology in Figure 11.\nMoreover, we also show several Ruozhiba-style ${ }^{9}$ logical reasoning problems created with personas in Figure 12. All the examples demonstrate that as long as we can clearly describe the requirements for the logical reasoning problem to be created, we can use a large variety of personas to steer the LLM to generate diverse logical reasoning problems that not only meet the requirements but are also highly relevant to the personas, even for whimsical Ruozhiba-style problems.\n\n[^4]![](https://cdn.mathpix.com/cropped/2024_09_12_4ecca495f94ca08827cag-11.jpg?height=817&width=1310&top_left_y=269&top_left_x=402)\n\nFigure 11: Logical reasoning problems created by our proposed persona-driven methodology\n\n![](https://cdn.mathpix.com/cropped/2024_09_12_4ecca495f94ca08827cag-11.jpg?height=668&width=1503&top_left_y=1170&top_left_x=303)\n\nFigure 12: Ruozhiba-style logical reasoning problems created with various personas. Note that Logical Prompt 3 in this figure is a simplified prompt. In practice, we need to specifically define a Ruozhiba-style logical reasoning problem in this prompt in order to obtain desired synthetic data.\n\nFor more examples, please refer to the 50,000 synthetic reasoning problems we have released.",
        "### 4.3 Instructions": "The end users of LLMs are ultimately humans. We can use Persona Hub to simulate a variety of users to understand their typical requests for LLM assistance, resulting in diverse instructions (i.e., user prompts).\nFigure 13 shows two typical persona-driven prompts for synthesizing instructions, corresponding to the zero-shot prompting and persona-enhanced few-shot prompting methods described in Section 3. The zero-shot method does not rely on any existing instruction dataset and allows the LLM\n\n![](https://cdn.mathpix.com/cropped/2024_09_12_4ecca495f94ca08827cag-12.jpg?height=819&width=1202&top_left_y=268&top_left_x=451)\n\nFigure 13: Two typical prompts used for creating instructions (i.e., user prompts).\nto generate various instructions based on different personas. In contrast, the persona-enhanced few-shot method requires existing instruction datasets (e.g., we use WildChat (Zhao et al., 2024) in our experiments) to sample some instructions as demonstrations and involves inferring the associated personas of these instructions through the Text-to-Persona method described in Section 2.1. While this approach is more complex, it results in synthesized instructions that more closely resembles instructions from real users.\nWith diverse instructions created using Persona Hub, which typically represent the first turn of a user-LLM conversation, we can easily generate their subsequent conversational turns using an LLM, resulting in a large number of simulated user-LLM conversations, which will be valuable for enhancing the LLM's instruction-following and conversational abilities. Furthermore, we can even adopt a similar approach by selecting two personas from Persona Hub and having LLMs role-play both, thereby simulating conversations (Jandaghi et al., 2023) between two real people.\nAs Figure 1 has already shown some instructions created using this methodology, we skip showing examples here. Readers interested in more examples can refer to the released 50,000 instructions synthesized through 0 -shot and persona-enhanced 2 -shot prompting.",
        "### 4.4 Knowledge-rich Texts": "In addition to synthesizing instructions that can enhance the instruction tuning of LLMs, the persona-driven methodology can be easily adapted to create knowledge-rich plain text that benefits pre-training and post-training of LLMs. As illustrated in Figure 14, we can prompt an LLM to write a Quora ${ }^{10}$ article ${ }^{11}$ using a persona sampled from Persona Hub. This approach elicits the LLM's corresponding knowledge and perspective, resulting in highly informative and knowledge-rich content. By scaling this process with 1 billion personas in Persona Hub, we can easily obtain a vast array of knowledge-rich texts that cover almost any topic across various levels of granularity.\n\n[^5]![](https://cdn.mathpix.com/cropped/2024_09_12_4ecca495f94ca08827cag-13.jpg?height=879&width=1492&top_left_y=276&top_left_x=314)\n\nFigure 14: Examples of knowledge-rich plain text synthesis with personas",
        "### 4.5 Game NPCs": 'A straightforward and practical application of Persona Hub is creating diverse NPCs (Non-Player Characters) at scale for games. As long as we can provide a game\'s background and world-building information to the LLM, we can prompt the LLM to project personas from Persona Hub (which are typically real-world personas) into characters within the game\'s world. In this way, we can significantly reduce the effort required for brainstorming NPCs during the game design process.\n\n![](https://cdn.mathpix.com/cropped/2024_09_12_4ecca495f94ca08827cag-13.jpg?height=849&width=1489&top_left_y=1619&top_left_x=318)\n\nFigure 15: NPC creation for the game "World of Warcraft" using personas in Persona Hub\n\n![](https://cdn.mathpix.com/cropped/2024_09_12_4ecca495f94ca08827cag-14.jpg?height=820&width=1508&top_left_y=219&top_left_x=300)\n\nFigure 16: NPC creation for the game "Moonlight Blade (Â§©Ê∂ØÊòéÊúàÂàÄ)" using Persona Hub\n\nFigure 15 and 16 show concrete examples where we use personas in Persona Hub to create game NPCs for the game "World of Warcraft ${ }^{12 "}$ and "Moonlight Blade ${ }^{13 "}$.',
        "### 4.6 Tool (Function) Development": "![](https://cdn.mathpix.com/cropped/2024_09_12_4ecca495f94ca08827cag-14.jpg?height=649&width=1489&top_left_y=1367&top_left_x=318)\n\nFigure 17: Examples of tool (function) creation with Persona Hub\nAs Section 4.3 demonstrates, Persona Hub can be used to simulate a wide variety of real users to anticipate their possible requests (i.e., instructions) to an LLM. Similarly, we can use Persona Hub to predict the tools (Cai et al., 2023; Schick et al., 2024) that users might need, so that we can pre-build these tools (functions) beforehand. When a real user makes a similar request, the LLM can directly call these pre-built tools to return results without having to build tools from scratch each time. This\n\n[^6]paradigm, introduced by Persona Hub, is a completely new solution that allows LLMs to better serve users. We believe it will have great potential in the future as LLMs become more democratized and multifunctional.\n\nFigure 17 shows examples of tools created with various personas. These tools provide functionalities that the personas may need (e.g., a cab driver needs to check traffic conditions) but cannot be accessed by an LLM, greatly expanding the range of services provided by the LLM. Note that although the tools in Figure 17 are just interface definitions, these definitions can be easily converted into code implementations, as shown in Figure 18.\n\n```\n\\ Code Implementation for the Species Identification Interface\n```\n\nFigure 18: The interface definitions (e.g., the species identification interface) in Figure 17 can be easily converted into code implementations by calling an LLM to implement them. The resulting pre-built tools can then be directly utilized by the LLM in the future, eliminating the need to build them from scratch each time.",
    },
    "## 5 Broad Impact and Ethical Concerns": {
        "## 5 Broad Impact and Ethical Concerns": "",
        "### 5.1 Broad Impact": "### 5.1.1 Paradigm Shift in Data Creation by Humans and LLMs\n\nTraditionally, it has been widely accepted that while LLMs excel at processing data (e.g., rewriting, annotation, or generating outputs/solutions to specific inputs), they are not particularly adept at creating new data. Consequently, the task of data creation has still largely been the domain of humans, and the collaboration paradigm between humans and LLMs has always been humans creating data and LLMs processing it (Maini et al., 2024). However, the introduction of our proposed\npersona-driven methodology potentially revolutionizes this paradigm. With Persona Hub, LLMs are no longer confined to processing existing data; they can now create various types of new data from a multitude of perspectives, much like the diverse population of the world.\nWhile the current capabilities of LLMs may not yet fully replace humans in fulfilling the mission of data creation-whether in terms of data quality or breadth-the ongoing advancements in LLM capabilities suggest a future where LLMs will increasingly excel in data creation. As LLMs continue to improve, both the quality and breadth of the data they can create will also likely enhance, leading us to a point where LLMs may fully take on the role of data creation. When this day arrives, we will no longer be constrained (Villalobos et al., 2024) by the limited high-quality human-produced real-world data ${ }^{14}$. Persona Hub ensures the diversity and coverage of synthetic data, significantly mitigating concerns about the negative impacts (Shumailov et al., 2023; Dohmatob et al., 2024) of synthetic data on model training. This may effectively eliminate the data bottleneck, thereby pushing the scaling law to its limit.\n\n### 5.1.2 Reality Simulation\n\nIn Section 4.3 and 4.6, we have demonstrated that Persona Hub can represent a vast array of realworld individuals with its 1 billion personas. By employing these personas to simulate and infer the potential needs and behaviors of real users, we can not only allow LLMs to autonomously prepare for upcoming use cases (queries), but also pave the way for LLMs to effectively mimic the real world, thereby creating many new opportunities. For instance, companies can use this method to predict how different types of users might react to a new product launch; governments can foresee the public's response to new legislation, considering various population group; in online services that require user profiling and behavior modeling, Persona Hub can facilitate the simulation of diverse user behaviors, significantly alleviating the cold start challenge.\nRecent research on LLM roleplay, agent collaboration (Liu et al., 2023; Wang et al., 2024), strategic reasoning (Gandhi et al., 2023; Zhang et al., 2024), and related areas can, of course, be facilitated by the vast and diverse personas in Persona Hub. More ambitiously, the 1 billion personas can even sustain a well-organized society within a virtual world, such as sandbox environments (Park et al., 2023), online games, parallel worlds, or the metaverse, using the method discussed in Section 4.5 to simulate operations with powerful LLMs. This virtual society can serve as a testing ground for new policies, radical initiatives, and social dynamics, providing valuable insights before real-world implementation. By creating a controlled environment where diverse personas interact, we can observe emergent behaviors, test hypotheses, and refine strategies in a risk-free setting. This can not only help deepen our understanding of complex systems but also speed up innovation by facilitating rapid iteration and experimentation.\n\n### 5.1.3 Full Memory Access of LLMs\n\nWhen we interact with an LLM in a specific scenario, we can only elicit a fraction of its memory and capabilities, and we are unable to fully access the vast knowledge encapsulated within the LLM. However, Persona Hub potentially offers access to the full memory of an LLM because the 1 billion personas in Persona Hub can tap into almost every perspective and piece of information encoded within the LLM.\n\nBy leveraging these 1 billion personas, we can create diverse queries and obtain solutions from a target LLM, thereby transforming the LLM's comprehensive memory (parameters) into synthetic data in textual form. If we consider an LLM as a parameterized compression of world knowledge, then Persona Hub can be viewed as a distributed carrier-based compression ${ }^{15}$ of world knowledge, as demonstrated in Figure 2. This distributed carrier-based compression provides us with an\n\n[^7]opportunity to decompress the LLM's parameters back into world knowledge and information it has ever learned (e.g., using the method discussed in Section 4.4).\nHowever, considering that the current Persona Hub is still in a very preliminary stage and that today's LLMs are not yet capable of losslessly converting their memory into synthetic data due to inevitable hallucination (Xu et al., 2024), the breadth and quality of the synthetic data generated through this methodology are still limited. Nevertheless, as Persona Hub continues to improve and scale, and as LLMs become more powerful (with less hallucination), we can look forward to a day when it will be possible to nearly losslessly extract the full memory of an LLM into plain text.",
        "### 5.2 Ethical Concerns": "### 5.2.1 Training Data Security and Threats to Current LLM Dominance\n\nAs discussed in Section 5.1.3, Persona Hub offers an opportunity to access the full memory of a target LLM. However, this also introduces a significant issue: the security of the training data. All data synthesized through the target LLM essentially represents a form of its seen training data. Therefore, the process of extensively extracting a target LLM's memory is essentially dumping its training data, even though this process is generally lossy.\nMoreover, if we employ the method described in Section 4.3 to synthesize instructions (i.e., user prompts) that nearly covers all use cases to query a target LLM to obtain its outputs at scale, there is a high risk that the target LLM's knowledge, intelligence, and capabilities could be extracted and replicated. This poses a challenge to the leading position of the most powerful LLMs, as we have already validated in Section 4.1 through mathematical reasoning.\nGiven that current LLMs generally share similar architectures and their performance advantage primarily lies in their data, this work is likely to impact the current practices and may potentially serve as a turning point, accelerating the shift in the competitive landscape of LLMs from one that heavily depends on data advantage to one that focuses on more advanced technologies.\n\n### 5.2.2 Miscellaneous\n\nSynthetic data presents a general concern of misinformation and fake news, which has been frequently discussed in previous research (Pan et al., 2023). Persona Hub potentially amplifies this issue, as diverse personas bring diverse writing styles, making machine-generated texts harder to distinguish from human-generated content (Chakraborty et al., 2023). This increased difficulty in detection may worsen issues related to data contamination, where synthetic data is mixed with real data, potentially skewing research results and public information.",
    },
    "## 6 Conclusion and Future Work": "\nWe propose a novel persona-driven data synthesis methodology and present Persona Hub, a collection of 1 billion diverse personas automatically curated from web data. We show that this methodology can facilitate the scaling of synthetic data creation across various scenarios, demonstrating its potential to revolutionize creation and applications of synthetic data, and its prospects as a general data synthesis engine for both research and practice.\nAs the first version of Persona Hub, although it already contains 1 billion personas, the descriptions of these personas are focused only on major aspects and lack fine-grained details (e.g., preferences for colors and numbers; specific family backgrounds, historical contexts, and life experiences). We plan to refine the personas in subsequent versions of Persona Hub, aiming for their descriptions to be as detailed as those found in Wikipedia articles about individuals. These more detailed persona descriptions will make each persona more unique, thereby scaling up Persona Hub and fostering more opportunities for synthetic data creation, while also empowering practical applications such as personalized conversations (e.g., character.ai).\n\nAlso, while this work only explores data synthesis with text-based LLMs, the methodology should also be applicable to multimodal LLMs. Therefore, we will explore multi-modal synthetic data creation as a future direction. Moreover, given that specific personas can elicit corresponding perspectives from LLMs, we are curious about the possibilities of using some super personas to guide LLMs to explore beyond the scope of existing knowledge. This may provide a new approach to tapping into the super intelligence of LLMs, which will be studied in the future.\n",
}

aic_dict = {
    "Abstract": "\nWe propose a novel persona-driven data synthesis methodology that leverages various perspectives within a large language model (LLM) to create diverse synthetic data. To fully exploit this methodology at scale, we introduce Persona Hub - a collection of 1 billion diverse personas automatically curated from web data. These 1 billion personas ( $\\sim 13 \\%$ of the world's total population), acting as distributed carriers of world knowledge, can tap into almost every perspective encapsulated within the LLM, thereby facilitating the creation of diverse synthetic data at scale for various scenarios. By showcasing Persona Hub's use cases in synthesizing high-quality mathematical and logical reasoning problems, instructions (i.e., user prompts), knowledge-rich texts, game NPCs and tools (functions) at scale, we demonstrate persona-driven data synthesis is versatile, scalable, flexible, and easy to use, potentially driving a paradigm shift in synthetic data creation and applications in practice, which may have a profound impact on LLM research and development. DISCLAIMER: Persona Hub can facilitate synthetic data creation at a billion-scale to simulate diverse inputs (i.e., use cases) from a wide variety of real-world users. If this data is used as input to query a target LLM to obtain its outputs at scale, there is a high risk that the LLM's knowledge, intelligence and capabilities will be dumped and easily replicated, thereby challenging the leading position of the most powerful LLMs (e.g., our approach allows a $7 B L L M$ to achieve $65 \\%$ on MATH, matching the performance of gpt-4-turbo-preview). This tech report is for research purposes only. It is crucial to avoid misuse and ensure ethical and responsible application. We discuss its broad impact and potential concerns in detail in Section 5.\n\n![](https://cdn.mathpix.com/cropped/2024_09_12_4ecca495f94ca08827cag-01.jpg?height=782&width=1489&top_left_y=1493&top_left_x=318)\n\nFigure 1: Personas can work with a wide range of data synthesis prompts (e.g., create a math problem or a user prompt) to guide an LLM to synthesize data with corresponding perspectives. The 1 billion personas in Persona Hub can facilitate synthetic data creation for various data synthesis scenarios at a billion scale.\n",
    "Introduction": '\nAs synthetic data (Bauer et al., 2024; Liu et al., 2024), typically referring to data generated by models or algorithms rather than directly by humans, becomes increasingly valued (Li et al., 2023b) for training large language models (LLMs), there is a growing interest in data synthesis using LLMs: by simply specifying a data synthesis prompt, an LLM is expected to produce desirable synthetic data.\nIn practice, however, it is non-trivial to create synthetic data at scale: while we can easily scale up the quantity of synthetic data, it is difficult to ensure its diversity scales up as well. Without considering sampling ${ }^{1}$, an LLM can only produce 1 instance given a data synthesis prompt. Therefore, to create diverse synthetic data at scale (e.g., 1 billion diverse math problems), a large number of diverse prompts are needed.\n\nPrevious research tends to diversify the data synthesis prompt through the following two paradigms, but unfortunately, neither can practically achieve scalable synthetic data creation:\n\n- Instance-driven: This approach diversifies the data synthesis prompt by leveraging a seed corpus (i.e., creating new instances based on the instances in the seed corpus). Representative studies include Wang et al. (2022) and Yu et al. (2023). However, under this paradigm, the diversity of the synthesized data mainly comes from the seed instances, making it difficult to truly extend beyond the seed corpus. Given the limited size of a seed corpus in most practical scenarios, it is challenging for this paradigm to scale up the creation of synthetic data.\n- Key-point-driven: This approach diversifies the data synthesis prompt with a curated comprehensive list of key points (or concepts) that can be a topic, a subject, or any knowledge we expect synthetic data to encompass. Representative studies include Li et al. (2024b) and Huang et al. (2024). However, this methodology also faces difficulties in scaling synthetic data creation: it is practically prohibitive to curate a comprehensive list by enumerating all key points across different levels of granularity, unless limited to a narrow and specific domain (e.g., mathematics).\n\nTo practically achieve diverse synthetic data creation at scale, we propose a novel persona-driven data synthesis methodology. This is inspired by the observation that simply adding a persona to a data synthesis prompt can steer the LLM towards the corresponding perspective to create distinctive synthetic data, as shown in Figure 1. Since almost any LLM use case can be associated with a specific persona, we can create all-encompassing synthetic data at scale as long as we construct a comprehensive persona collection.\n\n![](https://cdn.mathpix.com/cropped/2024_09_12_4ecca495f94ca08827cag-02.jpg?height=508&width=1489&top_left_y=1687&top_left_x=318)\n\nFigure 2: From a compression perspective (Del√©tang et al., 2023; Ge et al., 2024), Persona Hub ( $\\sim 10^{10}$ tokens) can be seen as the compressed form of world knowledge (public web text for training LLMs, $\\sim 10^{14}$ tokens) into distributed carriers. On the other hand, the public web text can be seen as the decompressed content created by these personas with their knowledge and experiences.\n\n[^0]Fortunately, personas are very easy to scale up. From massive web data, we automatically construct Persona Hub - a persona collection containing 1 billion diverse personas ( $\\sim 13 \\%$ of the world\'s total population). As Figure 2 shows, these 1 billion personas can be regarded as distributed carriers of world knowledge, and each individual can be associated with their unique knowledge, experience, interest, personality and profession; thus, they can tap into almost every perspective encapsulated within the LLM to create diverse synthetic data at scale, without being limited by the size of a seed corpus. Moreover, in contrast to key points that typically work with specific data synthesis prompts, personas can be combined with almost any data synthesis prompt, benefiting from an LLM\'s strong roleplay ability (Shanahan et al., 2023; Li et al., 2023a; Choi \\& Li, 2024; Wang et al., 2024), making them generally applicable to a variety of data synthesis scenarios.\nWe showcase Persona Hub\'s use cases in large-scale creation of math and logical reasoning problems, instructions (i.e., user prompts), broad-coverage knowledge-rich texts, game NPCs, and tool (function) development. We demonstrate that persona-driven data synthesis is versatile, scalable, flexible, and easy to use, potentially driving a paradigm shift in synthetic data creation and applications in practice, which may have a profound impact on LLM research and development.\n\nTo facilitate research in persona-driven data synthesis, we initially release 200,000 personas from Persona Hub and following synthetic data samples we created with various personas, including:\n\n- 50,000 math problems\n- 50,000 instructions\n- 10,000 game NPCs\n- 50,000 logical reasoning problems\n- 10,000 knowledge-rich texts\n- 5,000 tools (functions)\n\nWe are open to releasing more data when we can better assess the potential risks and concerns, which will be discussed in detail in Section 5.\n\nNote: Our proposed methodology is applicable to almost any popular LLM ${ }^{2}$. The prompts shown in the figures throughout this paper are not exactly the prompt strings we used in our experiments; instead, they are simplified to fit the space and better illustrate the concepts. Interested readers can easily verify our methodology using the persona samples we have released. It is also worth noting that the main focus of this work is on creating new synthetic data, unlike much previous research that focuses on generating synthetic outputs for specific inputs (e.g., a math problem). Therefore, we use the terms "create" and "synthesize" interchangeably throughout the paper.\n',
    "Conclusion": "\nWe propose a novel persona-driven data synthesis methodology and present Persona Hub, a collection of 1 billion diverse personas automatically curated from web data. We show that this methodology can facilitate the scaling of synthetic data creation across various scenarios, demonstrating its potential to revolutionize creation and applications of synthetic data, and its prospects as a general data synthesis engine for both research and practice.\nAs the first version of Persona Hub, although it already contains 1 billion personas, the descriptions of these personas are focused only on major aspects and lack fine-grained details (e.g., preferences for colors and numbers; specific family backgrounds, historical contexts, and life experiences). We plan to refine the personas in subsequent versions of Persona Hub, aiming for their descriptions to be as detailed as those found in Wikipedia articles about individuals. These more detailed persona descriptions will make each persona more unique, thereby scaling up Persona Hub and fostering more opportunities for synthetic data creation, while also empowering practical applications such as personalized conversations (e.g., character.ai).\n\nAlso, while this work only explores data synthesis with text-based LLMs, the methodology should also be applicable to multimodal LLMs. Therefore, we will explore multi-modal synthetic data creation as a future direction. Moreover, given that specific personas can elicit corresponding perspectives from LLMs, we are curious about the possibilities of using some super personas to guide LLMs to explore beyond the scope of existing knowledge. This may provide a new approach to tapping into the super intelligence of LLMs, which will be studied in the future.\n",
}
